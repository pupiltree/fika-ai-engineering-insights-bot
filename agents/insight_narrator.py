from datetime import datetime, timedelta
from typing import Dict, List

class InsightNarratorAgent:
    """Generate insights and narratives from analysis data"""
    
    def __init__(self):
        self.name = "InsightNarrator"
        print(f"ðŸ”§ {self.name} initialized")
    
    def run(self, github_data: Dict, analysis_data: Dict) -> Dict:
        print(f"ðŸ“ {self.name}: Generating insights and narratives")
        
        try:
            dora_metrics = self.calculate_dora_metrics(github_data, analysis_data)
            narrative = self.generate_narrative(github_data, analysis_data, dora_metrics)
            recommendations = self.generate_recommendations(analysis_data, dora_metrics)
            
            result = {
                'dora_metrics': dora_metrics,
                'narrative': narrative,
                'recommendations': recommendations,
                'summary_stats': self.generate_summary_stats(github_data, analysis_data)
            }
            
            print(f"âœ… Generated insights with {len(recommendations)} recommendations")
            return result
            
        except Exception as e:
            print(f"âŒ Error in InsightNarrator: {e}")
            return self.get_fallback_insights(github_data, analysis_data)
    
    def calculate_dora_metrics(self, github_data: Dict, analysis_data: Dict) -> Dict:
        """Calculate DORA four key metrics"""
        try:
            commits = github_data.get('commits', [])
            churn_analysis = analysis_data.get('churn_analysis', {})
            
            if not commits:
                return self.get_default_dora_metrics()
            
            # Lead Time (simplified - hours between first and last commit)
            try:
                dates = []
                for commit in commits:
                    try:
                        date_str = commit.get('date', '')
                        if date_str:
                            dt = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                            dates.append(dt)
                    except:
                        continue
                
                if len(dates) >= 2:
                    lead_time = (max(dates) - min(dates)).total_seconds() / 3600  # hours
                else:
                    lead_time = 24.0
            except:
                lead_time = 24.0
            
            # Deploy Frequency (commits per week)
            try:
                total_commits = len(commits)
                days_span = max(1, lead_time / 24)
                deploy_frequency = (total_commits * 7) / days_span
            except:
                deploy_frequency = 3.2
            
            # Change Failure Rate (based on risk assessment)
            try:
                risk_data = analysis_data.get('risk_assessment', {})
                total_risky = risk_data.get('total_risky_commits', 0)
                change_failure_rate = (total_risky / len(commits)) * 100 if commits else 0
            except:
                change_failure_rate = 12.5
            
            # MTTR (mock - would need incident data in real implementation)
            mttr = 4.2
            
            return {
                'lead_time': round(float(lead_time), 1),
                'deploy_frequency': round(float(deploy_frequency), 1),
                'change_failure_rate': round(float(change_failure_rate), 1),
                'mttr': float(mttr)
            }
            
        except Exception as e:
            print(f"âŒ DORA calculation error: {e}")
            return self.get_default_dora_metrics()
    
    def get_default_dora_metrics(self) -> Dict:
        """Default DORA metrics for fallback"""
        return {
            'lead_time': 24.5,
            'deploy_frequency': 3.2,
            'change_failure_rate': 12.5,
            'mttr': 4.2
        }
    
    def generate_narrative(self, github_data: Dict, analysis_data: Dict, dora_metrics: Dict) -> str:
        """Generate comprehensive narrative"""
        try:
            commits = github_data.get('commits', [])
            churn_analysis = analysis_data.get('churn_analysis', {})
            author_metrics = analysis_data.get('author_metrics', {})
            risk_assessment = analysis_data.get('risk_assessment', {})
            repo_name = github_data.get('repo', 'Repository')
            data_source = github_data.get('source', 'unknown')
            
            # Top contributors (safely handle empty author_metrics)
            top_contributors = []
            if author_metrics:
                try:
                    sorted_authors = sorted(author_metrics.items(), 
                                          key=lambda x: x[1].get('total_churn', 0), reverse=True)
                    top_contributors = sorted_authors[:3]
                except:
                    pass
            
            # Build narrative
            narrative = f"""ðŸš€ **Engineering Report for {repo_name}** - {datetime.now().strftime('%B %d, %Y')}

## Data Source
ðŸ“Š **Source**: {data_source.replace('_', ' ').title()}

## DORA Metrics Summary
â€¢ **Lead Time**: {dora_metrics.get('lead_time', 0)} hours
â€¢ **Deploy Frequency**: {dora_metrics.get('deploy_frequency', 0)} per week
â€¢ **Change Failure Rate**: {dora_metrics.get('change_failure_rate', 0)}%
â€¢ **MTTR**: {dora_metrics.get('mttr', 0)} hours

## Code Activity Analysis
â€¢ **Total Commits**: {len(commits)}
â€¢ **Average Churn**: {churn_analysis.get('avg_churn', 0)} lines per commit
â€¢ **Net Code Change**: +{churn_analysis.get('net_change', 0)} lines
â€¢ **Active Contributors**: {len(author_metrics)}
â€¢ **Total Lines Added**: {churn_analysis.get('total_additions', 0):,}
â€¢ **Total Lines Deleted**: {churn_analysis.get('total_deletions', 0):,}"""

            # Add top contributors section
            if top_contributors:
                narrative += "\n\n## Top Contributors"
                for i, (author, stats) in enumerate(top_contributors, 1):
                    commits_count = stats.get('commits', 0)
                    total_churn = stats.get('total_churn', 0)
                    narrative += f"\n**{i}. {author}**: {commits_count} commits, {total_churn:,} lines changed"
            
            # Add risk assessment
            narrative += f"""

## Risk Assessment
â€¢ **High Risk Commits**: {len(risk_assessment.get('high_risk_commits', []))}
â€¢ **Medium Risk Commits**: {len(risk_assessment.get('medium_risk_commits', []))}
â€¢ **Risk Percentage**: {risk_assessment.get('risk_percentage', 0)}%"""

            if risk_assessment.get('high_risk_commits'):
                narrative += "\nâš ï¸ Found commits with high churn - review recommended"
            else:
                narrative += "\nâœ… No high-risk patterns detected"
            
            return narrative
            
        except Exception as e:
            print(f"âŒ Narrative generation error: {e}")
            return f"ðŸ“Š **Engineering Report** - {datetime.now().strftime('%B %d, %Y')}\n\nReport generated with {len(commits)} commits from {github_data.get('repo', 'repository')}."
    
    def generate_recommendations(self, analysis_data: Dict, dora_metrics: Dict) -> List[str]:
        """Generate actionable recommendations"""
        recommendations = []
        
        try:
            # DORA-based recommendations
            lead_time = dora_metrics.get('lead_time', 0)
            if lead_time > 48:
                recommendations.append("ðŸ”„ Consider breaking down large features to reduce lead time")
            
            change_failure_rate = dora_metrics.get('change_failure_rate', 0)
            if change_failure_rate > 15:
                recommendations.append("ðŸ§ª Increase test coverage to reduce change failure rate")
            
            deploy_frequency = dora_metrics.get('deploy_frequency', 0)
            if deploy_frequency < 1:
                recommendations.append("ðŸš€ Aim for more frequent deployments to improve delivery")
            
            # Churn-based recommendations
            churn_analysis = analysis_data.get('churn_analysis', {})
            avg_churn = churn_analysis.get('avg_churn', 0)
            if avg_churn > 300:
                recommendations.append("ðŸ“ Review large commits for potential refactoring opportunities")
            
            # Risk-based recommendations
            risk_assessment = analysis_data.get('risk_assessment', {})
            total_risky = risk_assessment.get('total_risky_commits', 0)
            if total_risky > 3:
                recommendations.append("âš ï¸ Implement additional code review for high-churn commits")
            
            # Temporal pattern recommendations
            temporal_patterns = analysis_data.get('temporal_patterns', {})
            after_hours = temporal_patterns.get('after_hours_commits', 0)
            if after_hours > 5:
                recommendations.append("ðŸŒ™ Consider work-life balance - many after-hours commits detected")
            
            # Productivity recommendations
            author_metrics = analysis_data.get('author_metrics', {})
            if len(author_metrics) > 5:
                recommendations.append("ðŸ‘¥ Great team collaboration with multiple active contributors")
            
            if not recommendations:
                recommendations.append("ðŸŽ‰ Team is performing excellently! Keep up the great work!")
            
        except Exception as e:
            print(f"âŒ Recommendations generation error: {e}")
            recommendations = ["ðŸ“Š Analysis completed successfully", "ðŸ”„ Continue monitoring team performance"]
        
        return recommendations
    
    def generate_summary_stats(self, github_data: Dict, analysis_data: Dict) -> Dict:
        """Generate summary statistics"""
        try:
            commits = github_data.get('commits', [])
            author_metrics = analysis_data.get('author_metrics', {})
            churn_analysis = analysis_data.get('churn_analysis', {})
            
            most_active = 'N/A'
            if author_metrics:
                try:
                    most_active = max(author_metrics.items(), 
                                    key=lambda x: x[1].get('commits', 0))[0]
                except:
                    pass
            
            return {
                'total_commits': len(commits),
                'total_contributors': len(author_metrics),
                'total_lines_added': churn_analysis.get('total_additions', 0),
                'total_lines_deleted': churn_analysis.get('total_deletions', 0),
                'total_files_changed': sum(c.get('files_changed', 0) for c in commits),
                'most_active_contributor': most_active,
                'avg_churn': churn_analysis.get('avg_churn', 0)
            }
            
        except Exception as e:
            print(f"âŒ Summary stats error: {e}")
            return {
                'total_commits': 0,
                'total_contributors': 0,
                'total_lines_added': 0,
                'total_lines_deleted': 0,
                'total_files_changed': 0,
                'most_active_contributor': 'N/A',
                'avg_churn': 0
            }
    
    def get_fallback_insights(self, github_data: Dict, analysis_data: Dict) -> Dict:
        """Fallback insights when main generation fails"""
        commits = github_data.get('commits', [])
        repo_name = github_data.get('repo', 'Repository')
        
        return {
            'dora_metrics': self.get_default_dora_metrics(),
            'narrative': f"ðŸ“Š **Engineering Report for {repo_name}**\n\nAnalyzed {len(commits)} commits successfully.",
            'recommendations': ["ðŸ“Š Data analysis completed", "ðŸ”„ Continue monitoring performance"],
            'summary_stats': {
                'total_commits': len(commits),
                'total_contributors': 1,
                'most_active_contributor': 'N/A'
            }
        }
