# agents/insight_narrator.py

from typing import Dict, List
import datetime


def generate_insights(analysis: Dict) -> Dict:
    """Turn commit and PR analysis into DORA-style narrative insights."""

    insights = []

    # ğŸ§® DORA: Deployment Frequency (PR count)
    pr_summary = analysis.get("pr_summary", {})
    pr_count = pr_summary.get("total_prs", 0)
    if pr_count == 0:
        insights.append("âš ï¸ No PR activity found. Engineering velocity might be low.")
    else:
        insights.append(f"ğŸš€ Deployment Frequency: {pr_count} PRs merged during the period.")

    # â±ï¸ DORA: Lead Time for Changes
    lead_time = pr_summary.get("avg_lead_time_hrs")
    if lead_time:
        hours = round(lead_time, 2)
        insights.append(f"â±ï¸ Average lead time: {hours} hours from PR creation to merge.")

    # ğŸ”¥ DORA: Change Failure Rate â€” proxy with churn spikes
    churn_spikes = analysis.get("churn_spikes", [])
    if churn_spikes:
        insights.append(f"âš ï¸ High churn detected in {len(churn_spikes)} commits. Possible quality risks.")
        flagged_authors = set([c["author"] for c in churn_spikes])
        insights.append(f"ğŸ‘€ Authors with high churn: {', '.join(flagged_authors)}")
    else:
        insights.append("âœ… No high-risk churn spikes detected.")

    # ğŸ“Š Churn Summary
    commit_summary = analysis.get("commit_churn_summary", [])
    for author_data in commit_summary:
        insights.append(
            f"ğŸ‘¤ {author_data['author']} made {author_data['commit_count']} commits "
            f"(+{author_data['additions']} / -{author_data['deletions']} lines, "
            f"{author_data['files_changed']} files changed)"
        )

    # Generate timestamped header
    today = datetime.date.today()
    headline = f"ğŸ“… Weekly Engineering Report â€” {today.strftime('%B %d, %Y')}"
    
    return {
        "headline": headline,
        "insights": insights
    }


# Local test
if __name__ == "__main__":
    from data_harvester import harvest_data
    from diff_analyst import analyze_diff

    raw_data = harvest_data()
    analysis = analyze_diff(raw_data)
    summary = generate_insights(analysis)

    print(summary["headline"])
    print("\n".join(summary["insights"]))
